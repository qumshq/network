## 新的任务

### 1. 修正influence计算函数:heavy_check_mark:

### 2. 思考为什么要将无向图转换为有向图处理？:heavy_check_mark:

-->转换成有向图的做法不合理，应当修改回无向图

原使用line进行编码的时候是基于转换为有向图之后的进行编码的-->已修改为无向图

==总结：使用line编码时作者先将无向图转化为有向图(并且是默认每个无向边在邻接表中存储了2次如a-b边存储了a-b和b-a)，然后在主代码中查找种子时在有向图的基础上计算每个节点的影响力，在其他地方没有用到==

### 3. 进行多次的生产数据和实际数据的实验对比

目前进行了一两次实验，由于前几次使用1000个节点的图编码和训练花费太多时间，目前转战200节点图，正在调参中。

#### 实验消耗时间说明：

==1000个节点的数据训练以及编码过程耗时很长(np难问题)==    SDNE对一个1000节点的图使用SDNE编码训练100轮花费一整个下午的时间，速度比line慢很多，但这也可能是后面的轮数没有必要（最低误差出现在第8轮，然后增加，第19轮后上下浮动稳定），从中午一直训练到晚上11：33

主代码（进化模型）耗时情况：(1000个节点训练10轮接近花费1h20min，不过这是同时开了另一个corn在运行SDNE)，相比之下200个节点完成10轮进化模型训练的时间值花费了3min不到：

| ![耗时情况](E:\coursewares\SchoolCourses\大三了唉下\人工智能技术驱动的网络信息挖掘\230221_一些初步资料\ERL-d1\code\result_pics\耗时情况.jpg) | ![image-20230411143748576](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230411143748576.png) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |

### 4.模拟攻击:heavy_check_mark:

攻击边

取度最大的att_node_num个节点，每个节点按照其邻居的度大小尝试依次删除edge_for_node条边

攻击节点：为了保持编码任然适用（即不需要度图像进行重新编码，攻击节点模拟为将节点的所有边remove）

==受到攻击后的图使用==目前实现的两种想法：

1. 直接用来计算受到攻击后的当前种子集的影响力变化

   :heavy_check_mark:：在attack_simulation文件中，破坏边之后进行对比​

2. 使用同样的DQN参数和特征新选出一组种子集并查看影响力变化

   :heavy_check_mark:：重置angent.env中的图和特征编码，然后用pop[0]重新选择节点并返回影响力

   发现：重新使用特征选种子可能会比直接使用原和种子集效果更差。

### 问题处理

1. 生成图文件`../data/生成数据/ER_N=200_k=4_edgelist`中出现10个孤立点，但由于实际读图进行选择种子的时候也不会读取孤立点，因此没必要补充孤立点

   ---不行，选种子的时候似乎会(可能是随机)选中缺失节点，因此必须在编码已经读取图的时候进行补充

2. 思考：最终模型收敛的条件应该是100个DQN的avg值收敛而不是最优的pop[0]求出的最大影响力长期不变

### 待完成

#### 1. 调整参数继续训练得到更多实验结果

==对比应注意控制变量==

| 对比两种编码的影响变量 | 获得更大影响力的调节参数                    |
| ---------------------- | ------------------------------------------- |
| 编码维度dim            | 学习率                                      |
| 学习率                 | pop_size = 100# 种群数量                    |
|                        | randomWalkTimes  强化学习的随机步数         |
|                        | learningTimes  强化学习每次进化更换的个体数 |

#### 2. 继续仔细阅读2022年那篇论文  ==关键==

Influence_Maximization_in_Complex_Networks_by_Using_Evolutionary_Deep_Reinforcement_Learning

#### 3. piano论文，并思考  ==未阅读==

#### 4. 后续：改进强化学习部分

#### 5. 指导因子转换成$R_s$算子

##### 6. 代码进一步修改  ==不重要==：

1. 将生成文件夹步骤放入到对list中的图遍历的循环中。
2. 对plot的进一步完善
4. 画出种群平均影响力变化，两边进行对比

